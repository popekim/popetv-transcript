오늘 몰아서 비디오 4개쯤만 만들고 있는데 힘들어요. 그럼 목소리도 갈라지고 그래서 괜히 잡소리 하면 피곤할 것 같아서 저는 덜 피곤하고, 그 들으시는 분 더 피곤하게 할게요. 오랜만에 렌더링 프로그래밍 쪽을 얘기하려고 해요. 사실은 제가 렌더링 프로그래밍을 콘솔 쪽에서 출시를 위해 렌더링 프로그래밍 한 지 한 6개월 정도 지났기 때문이에요. 사실은 지난 6개월 동안 제가 특별히 따로 리서치를 한 주제가 없어서 할 말이 없었어요. 기억하시는 분도 있을 수도 있겠는데, 아주 예전에 제가 살아온 과정을 수필집이나 자서전 비슷하게 쓰자고 했던 출판사들이 몇 군데 있어요. 두 군데 있었나? 그때 자료를 정리해 정보를 뒤지다가 찾은 게 있었어요. 그걸 스프링패드에 놨었는데 스프링패드가 이번에 문 닫는다고 백업할 것 백업하라 해서, 보니까 예전에 작업할 때 거기 남겨놓은 여러 가지 노트들이 있더라고요. 그중에서 하나를 얘기하려고 해요.

오늘 얘기할 것은 early-z-rejection이라고 하죠. Z-buffer(depth buffer, 깊이버퍼)는 보통 다 아실 테고요. 깊이버퍼가 깊이에 따라 언제 일어나냐, 픽셀이 현재 그려 있는 그 화면에 그려져 있는 픽셀 깊이보다 훨씬 뒤쪽에 있으면 안 그려야 되잖아요? 그럼 그걸 깊이 버퍼 테스팅 해서 최종 화면은 안 보여주는 그런 건데요. 이게 사실 최적화의 개념은 아니었어요. 왜냐하면 최적화가 약간 들어가긴 하는데, 웬만한 파이프라인에서 요즘 가장 비싼 비용 (가장 속도가 느린)은 아무래도 쉐이더거든요. 픽셀 쉐이더 같은 경우, 온갖 조명 넣으면 픽셀 하나 계산하는 데 몇 백 사이클 돌겠죠. 그럼 그걸 다 계산하고 난 다음에야 그다음에 깊이 버퍼랑 비교를 하고, 그 깊이버퍼보다 높이 있으면 그려 주고, 아래 있으면 그때 rejection을 하는 거예요. 그래서 깊이 어퍼가 줄 수 있는 최적화의 개념은, 마지막 단계로 화면에 블렌딩 해서 보여주는 Output Merger라고도 많이 하는데, 그 Output-Merging 할 때 최적화를 해 주는 게 전부예요. 그전에 최적화가 중요한 것은, 아까도 말씀드렸듯이 그 픽셀 쉐이더 전에 최적화를 할 수 있는 게 좋죠. 그래서 이게 가능하도록 이전에 다른 버퍼를 조금 둬서, Vertex Shader에서 이미 깊이가 나오니까 그 깊이가 최종 깊이버퍼보다 뒤에 있으면 픽셀 쉐이더 안 돌리고 버린다(rejection). 그걸 rasterization 다음에 하는 거죠. rasterization이 픽셀 위치를 찾아내주니까요. 그걸 early-z라고 하는 거예요.

그걸 하려고 하는 건데, 여러 가지 문제가 있어요. 사실은 왜냐하면 최종적으로 깊이 버퍼가 이렇게 적용되면, 거기서 정보도 빼와야 하고 등 여러 가지가 있거든요. 여기서 중요한 개념은 그거거든요. 일단 Early rejection 버퍼는 최종 버퍼보다 좀 크기가 작다고 해야 할까요? 최종버퍼는 한 픽셀마다 깊이를 저장하잖아요. 예를 들어서 2x2, 총 4개 픽셀을 (4x4로 16개 될 수 있는 거고) 하나로 저장하는 개념이 있어요. 그 4개의 픽셀의 깊이보다, 지금 그리는 픽셀 깊이가 더 위에 있으면 그려라. 근데 이 모든 4개 픽셀이 지금 그려놓은 픽셀보다 훨씬 위에 있다면, 어느 거에 들어가든 간에 결과적으로 다 rejection 하는 개념이거든요. hierarchical이라고 하죠. hierarchy라고 하면 계층이죠. 픽셀 하나씩 되어있는 깊이 버퍼가 있고 그보다 하나 계층을 높여서 조금 더 course 하게 픽셀 4개씩 하나의 그룹으로 묶어요.

이거를 굉장히 많이 사용했어요. DirectX9 Graph 레벨에서 많이 사용했고, early-z 같은 경우는 처음에는 한쪽 Vendor에서만 (NVIDIA 또는 AMD) 시작을 한 건데, 이제 모든 그래픽카드가 지원을 한다고 보고 현재도 지원을 해요. 이거에 대한 스펙이 약간 바뀌었는지는 모르겠어요. 그런데 그러지 않은 것 같았어요. PS4를 다룰 때도 별로 다르지 않았던 것으로 기억해요. 중요한 것은 이걸로 인해 굉장히 많은 최적화를 했다는 거였어요. 스페이스 마린에서도 그랬고, 저희가 최적화한 것 중에 하나가 Cascaded shadow map이라고 있죠? Shadow 할 때 내 앞에서부터 10m 까지는 커버하는 셰도우맵 이미지 1024 by 1024, 그다음 10m부터 100m 까지가 1024 by 1024가 있다고 할게요. 그러면 앞에 있는 것에서 훨씬 해상도가 뛰어난 샤도우 맵을 만들 수 있죠. 그거를 할 때 shadow map 자체가 여러 가지 문제가 있어요. 조명에서부터 셰도우까지 떨어진 길이가 있잖아요. 이 길이가 커질수록 결과적으로 하늘 꼭대기에 있는 해(광원)를 막는 물체가 몇 개나 있겠어요? 사실 지면까지 내려왔을 때, 건물 구조물 높이부터 내가 있는 바닥까지 그만큼의 shadow map을 만들면 그 깊이가 있잖아요. [0, 1] 사이의 부동소수점 값이 되죠. 이 값이 몰릴수록 정밀도가 높아지고, 분산될수록 정밀도가 떨어져요.

그래서 이거를 최대한 필요한 범위(건물높이~지면)까지만 내려서 셰도우를 그리는 최적화 기법이 소개가 됐었죠? 아마 마이크로소프트 게임 fest에서 처음 나왔던 얘기 같아요. 저희도 그걸 스페이스 마린 때 적용 했었죠. 재밌는 게 뭐냐면, 이 범위를 더 좁힐 수도 있어요. 만약에 물체가 내 머리 위에 있다고 할게요. 이걸 내 머리까지 내린다. 그러면 이 위에 있는 물체를 어떻게든 shadow map에 그리긴 해야 하잖아요? 그러면 그려줄 때 이 shadow map의 near plane보다 위쪽에서 그려주면 이건 rejection 즉, 클리핑 되잖아요? 그래서 이 위에 있는 걸 near plane까지 내려서 겹치게 하는 기법이 있어요. 이걸 팬케이크처럼 겹치게 한다고 해서 pancaking 기법이라고 했어요. 만약에 near plane에 있는 것 중에 절반 정도가 팬케이킹이 되어 있다면, 그 뒤에 있는 모든 물체를 그릴 때 이미 Early rejection이 돼 있잖아요? Z-Buffer에 들어가 있으니까 그만큼 빨리 픽셀 쉐이더에서 안 돌리고 rejection이 들어가요. 굉장히 좋은 게 기법 중에 하나였는데, 팬케이킹에 문제가 있었어요. early-z-rejection에서 팬케익을 이만큼 줄였어요. 그러면 팬케익 위에 물체들은 그려야 하잖아요? 예를 들어 물체가 100개가 있다면, 이 100개의 물체가 전부 다 z가 0이 돼야 해요. near plane에 그려야 하기 때문이죠. 그러면 0으로 막 그리는 건데, 문제는 이거예요.

early-z-rejection이라는 자체가 개념이 뭐냐면, 32비트 부동소수점을 써서 [0, 1]까지의 개념이 아니라 (이것 역시 하드웨어 따라서 달라질 것 같긴 한데) 범위가 있는 거예요. 예를 들어 early-z를 집어넣을 때 [0, 1]까지 다 놓겠다는 얘기가 아니라, 섹션을 나눠서 1번째 [0, 0.1], 2번째 [0.1, 0.2]... 이렇게 나누는 거죠. 그래서 내가 지금 그리려고 하는 물체가 이 버퍼 [0.1, 0.2]이고, 내가 그리려고 하는 물체가 전 단계면 통과시키고, 그다음의 단계면 rejection 해야 하는 거죠. 처음에 그림 픽셀 z가 0.15에 있었고, 다음에 그리는 픽셀이 0.18이면 이건 rejection을 할 수 없어요. 0.15와 0.18이 [0.1, 0.2] 범위 내 하나의 같은 그룹으로 뭉친 것이기 때문이죠. 이게 early-z-rejection의 문제예요.

이 팬케이크의 문제가 뭐냐면, 모든 물체 z를 다 0에 집어넣잖아요? 모든 걸 0에 집어넣었을 때 뒤에 나중에 그리는 물체들을 0.01에 넣어도 early-z-rejection 할 수가 없어요. 왜냐면 같은 그룹에 속한 거니까 자기보다 위에 있을 수도 있고, 아래에 있을 수도 있기 때문이죠. 그래서 저희가 퍼포먼스에서 굉장히 많은 손해를 봤던 게, 팬케익 크기를 아무리 줄여도, 그 위에 있는 물체들이 많을 때 여기에 계속 over draw를 계속해야 되는 거예요. 그게 되게 심했어요.

그때 든 생각이, 내가 하드웨어 디자이너라면 early-z 범위를 정할 때 1번째 범위는 무조건 [0, 0]으로 설정했을 거예요. 그러니까 1번째 [0, 0]은 범위가 아니라 딱 0 하나로만 들어가도록 하는 거죠. 그러면 0인 순간에 그 위에 다른 물체들도 0이기 때문에 무조건 rejection을 하는 거예요. 이게 0.01이 되면 다음 섹션으로 가는 것이기 때문에 그것도 역시 rejection이 되는 거죠. 그러면 그 밑에는 어떻게 하던 관심이 없는데, 특히 팬케익이 제대로 작동하려면 1번째 범위 [0, 0] 있잖아요? 그건 범위가 아니라 하나의 값 0이어야만 한다 생각해요. [0, 0] 범위에 뭔가를 그리면, (Z-buffer를 프라임 한다고 하죠) 똑같은 곳에 들어가도 계속 rejection 되는 거예요. 반면에 [0, 0]이 아닌 부분 있잖아요? 그 부분에 대해서만 계층적으로 evaluation을 해주든 말든 그렇게 되는 거죠.

제 생각에 만약 하드웨어가 그렇게 디자인 됐으면 shadow map 만드는 코드가 30% 빨라졌을 것 같아요. 그렇게 범위를 좁힘으로써 큰 건물들 그릴 때 1번째 섹션(그게 [0, 0.1]이던 [0, 0.01]이든 간에)에 물체들이 엄청나게 들어갔기 때문에 그것만 최적화해도 엄청난 것이지 않을까 생각이 들어요. 하드웨어 처음 디자인했을 당시에는 이렇게 팬케익까지 하는 걸 생각은 안 했겠지만, 단순히 우리가 보통 Scene을 바라볼 때 총 범위 [near, far]까지 생각을 했을 테고요. 그걸 섹션 범위로 나누면 그래도 웬만한 거는 많이 early-rejection 이 되겠다고 기대한 것 같아요. 설사 그 뒤에 early-rejection이 안된다 해도, 픽셀 셰이더에서 돌린 다음에 최종 depth buffer에 들어가겠죠. 그 생각을 하고 하드웨어를 만든 것 같은데, 제 생각에는 정말 1번째 범위만은 [0, 0]으로 했으면 shadow map 만들었을 때 속도가 엄청 빨라지지 않았을까 해요.

어찌 보면 좀 특수한 유형이기도 한데, 그래서 shadow map이 없는 게임은 없기 때문에 굉장히 훌륭한 기법일 거라 생각하고요. 아니면은 early-z-rejection이 들어갈 때 그런 범위를 직접 프로그래밍 가능하게 해주는 게 어떨까 생각을 해요. 물론 하드웨어 자체에서 하는 것보다는 좀 느려질 수도 있겠지만, 그렇게라도 해주면 가능하지 않을까요? 예를 들어서 옛날에 Xbox 360 같은 경우는 SRGB 있잖아요? 그 Gamma Space, Linear Space. 사실 이걸 제대로 지원을 안 했었거든요. 제대로 하드웨어에서 지원 안 해줘서, 거기에다 Gamma Lookup table 넣어서 저희가 만들었어요. 그런 식으로 룩업 테이블만 가능한 정도도 괜찮지 않을까요. 과연 얼마나 느려질까.. 어셈블리에서는 별로 안 느려질 것 같은데요?

어쨌든 그런 생각이 들고 옛날에 했던 생각이었어요. 저 망상하는 거 좋아하잖아요. 그쪽 망상하는 거 좋았기 때문에 그냥 얘기를 하고 싶어 했고, 그 정도면 오늘 할 말은 다 한 것 같아요. 오랜만에 그래픽 프로그래밍 얘기하니까 신나긴 신나네요. 포프였습니다.